<!-- Generated by documentation.js. Update this documentation by updating the source code. -->

## MediaServer

### setCertificate

Set new DTLS certificates. Should be called before any Endpoint is established.

#### Parameters

*   `cert` **[String][1]** path of the certificate file
*   `key` **[String][1]** path of the key file

### getDTLSFingerprint

Get local DTLS fingerprint for this Media Server.

Returns **[String][1]** 

### terminate

Close async handlers so nodejs can exit nicely
Only call it once!

### enableLog

Enable or disable log level traces

#### Parameters

*   `flag` **[Boolean][2]** 

### enableDebug

Enable or disable debug level traces

#### Parameters

*   `flag` **[Boolean][2]** 

### setPortRange

Set UDP port range for encpoints

#### Parameters

*   `minPort` **Integer** Min UDP port
*   `maxPort` **Integer** Max UDP port \[Optional]

### setAffinity

Set node uv loop cpu affinity

#### Parameters

*   `cpu` **Integer** CPU core number

Returns **[boolean][2]** true if operation was successful

### setThreadName

Set node uv loop thread name.

Useful for debugging or tracing. Currently only supported
on Linux, fails on other platforms.
Length is limited to 16 bytes.

#### Parameters

*   `name` **[String][1]** thread name to set

Returns **[boolean][2]** true if operation was successful

### enableUltraDebug

Enable or disable ultra debug level traces

#### Parameters

*   `flag` **[Boolean][2]** 

### createEndpoint

Create a new endpoint object

#### Parameters

*   `ip` **[String][1]** External IP address of server, to be used when announcing the local ICE candidate
*   `params` **[Object][3]** Creation parameters

    *   `params.packetPoolSize` **[Number][4]** Packet pool size

Returns **[Endpoint][5]** The new created endpoing

### createOffer

Helper that creates an offer from capabilities
It generates a random ICE username and password and gets media server dtls fingerprint

#### Parameters

*   `capabilities` **[Object][3]** Media capabilities as required by SDPInfo.create

Returns **SDPInfo** SDP offer

### createRecorder

Create a new MP4 recorder

#### Parameters

*   `filename` **[String][1]** Path and filename of the recorded mp4 file
*   `params` **[Object][3]** Recording parameters (Optional)

    *   `params.refresh` **[Number][4]** Periodically refresh an intra on all video tracks (in ms)
    *   `params.waitForIntra` **[Boolean][2]** Wait until first video iframe is received to start recording media
    *   `params.timeShift` **[Number][4]** Buffer time in ms. Recording must be splicity started with flush() call
    *   `params.disableHints` **[Boolean][2]** Disable recording hint tracks. Note that this file won't be playable with the Player object;

Returns **[Recorder][6]** 

### createPlayer

Create a new MP4 player

#### Parameters

*   `filename` **[String][1]** Path and filename of the mp4 file

Returns **[Player][7]** 

### createStreamer

Create a new RTP streamer

Returns **[Streamer][8]** 

### createActiveSpeakerDetector

Create a new Active Speaker Detecrtor

### createRefresher

Create a new stream refresher

#### Parameters

*   `period` **type** Intra refresh period

### createIncomingStreamTrackReader

Create a new incoming track reader

#### Parameters

*   `intraOnly` **type** Intra frames only
*   `minPeriod` **type** Minimum period between frames

### createEmulatedTransport

Create a new emulated transport from pcap file

#### Parameters

*   `pcap`  
*   `filename` **[String][1]** PCAP filename and path

### getDefaultCapabilities

Get the default media server capabilities for each supported media type

Returns **[Object][3]** Object containing the capabilities by media ("audio","video")

## SDPManager

**Extends Emitter**

SDPManager

### getState

Get current SDP offer/answer state

Returns **[String][1]** one of "initial","local-offer","remote-offer","stabable".

### getTransport

Returns the Transport object created by the SDP O/A

Returns **[Transport][9]** 

### stop

Stop manager and associated tranports

### stopped

SDPManager stopped event

#### Parameters

*   `transport` **[SDPManager][10]** 

## ActiveSpeakerMultiplexer

**Extends Emitter**

ActiveSpeakerMultiplexer multiplex multiple incoming audio tracks into fewer outgoing tracks based on voice activity.

### setMinChangePeriod

Set minimum period between active speaker changes

#### Parameters

*   `minChangePeriod` **[Number][4]** 

### setMaxAccumulatedScore

Maximux activity score accumulated by an speaker

#### Parameters

*   `maxAcummulatedScore` **[Number][4]** 

### setNoiseGatingThreshold

Minimum db level to not be considered as muted

#### Parameters

*   `noiseGatingThreshold` **[Number][4]** 

### setMinActivationScore

Set minimum activation score to be electible as active speaker

#### Parameters

*   `minActivationScore` **[Number][4]** 

### addSpeaker

Add incoming track for speaker detection

#### Parameters

*   `track` **[IncomingStreamTrack][11]** 

### removeSpeaker

Remove track from speaker detection

#### Parameters

*   `track` **[IncomingStreamTrack][11]** 

### stop

Stop this transponder, will dettach the OutgoingStreamTrack

### activespeakerchanged

ActiveSpeakerMultiplexer new active speaker detected event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** Track that has been voice activated
*   `outgoingStreamTrack` **[IncomingStreamTrack][11]** Track that has been multiplexed into

### noactivespeaker

ActiveSpeakerMultiplexer active speaker removed event

#### Parameters

*   `outgoingStreamTrack` **[IncomingStreamTrack][11]** Track with no active speaker

### stopped

ActiveSpeakerMultiplexer stopped event

#### Parameters

*   `ActiveSpeakerMultiplexer` **[ActiveSpeakerMultiplexer][12]** 

## RecorderTrack

**Extends Emitter**

Track of the recorder associated to an incoming strem track

### getId

Get recorder track id

### getTrack

Get incoming stream track

Returns **[IncomingStreamTrack][11]** 

### isMuted

Check if the track is muted or not

Returns **[boolean][2]** muted

### mute

Mute/Unmute track
This operation will not change the muted state of the stream this track belongs too.

#### Parameters

*   `muting` **[boolean][2]** if we want to mute or unmute

### stop

Stop recording this track

### stopped

RecorderTrack stopped event

#### Parameters

*   `recorderTrack` **[RecorderTrack][13]** 

## Refresher

**Extends Emitter**

Periodically request an I frame on all incoming stream or tracks

### restart

Restart refreshing interval

#### Parameters

*   `period`  
*   `timeout` **[Number][4]** Refresh pedior in ms

### add

Add stream or track to request

#### Parameters

*   `streamOrTrack` **(IncomintgStream | [IncomingStreamTrack][11])** 

### remove

Remove stream or track to request

#### Parameters

*   `streamOrTrack` **(IncomintgStream | [IncomingStreamTrack][11])** 

### stop

Stop refresher

### refreshing

Refresher event to indicate that refesh is taking place

#### Parameters

*   `refreser` **[Refresher][14]** 

### stopped

Refresher stopped event

#### Parameters

*   `refresher` **[Refresher][14]** 

## Streamer

**Extends Emitter**

An streamer allows to send and receive plain RTP over udp sockets.
This allows both to bridge legacy enpoints or integrate streaming/broadcasting services.

### createSession

Creates a new streaming session from a media description

#### Parameters

*   `media` **MediaInfo** Media codec description info
*   `params` **[Object][3]** Network parameters \[Optional]

    *   `params.local` **[Object][3]** Local parameters

        *   `params.local.port` **[Number][4]** receiving port
    *   `params.remote` **[Object][3]** Remote parameters

        *   `params.remote.ip` **[String][1]** Sending ip address
        *   `params.remote.port` **[Number][4]** Sending port
    *   `params.noRTCP` **[Number][4]** Disable sending rtcp

Returns **[StreamerSession][15]** The new streaming session

### stop

Stop all streaming sessions and frees resources

### stopped

Streamer stopped event

#### Parameters

*   `streamer` **[Streamer][8]** 

## ActiveSpeakerDetector

**Extends Emitter**

ActiveSpeakerDetector accumulate received voice activity and fires an event when it changes

### setMinChangePeriod

Set minimum period between active speaker changes

#### Parameters

*   `minChangePeriod` **[Number][4]** 

### setMaxAccumulatedScore

Maximux activity score accumulated by an speaker

#### Parameters

*   `maxAcummulatedScore` **[Number][4]** 

### setNoiseGatingThreshold

Minimum db level to not be considered as muted

#### Parameters

*   `noiseGatingThreshold` **[Number][4]** 

### setMinActivationScore

Set minimum activation score to be electible as active speaker

#### Parameters

*   `minActivationScore` **[Number][4]** 

### addSpeaker

Add incoming track for speaker detection

#### Parameters

*   `track` **[IncomingStreamTrack][11]** 

### removeSpeaker

Remove track from speaker detection

#### Parameters

*   `track` **IncomingStreamTrakc** 

### stop

Stop this transponder, will dettach the OutgoingStreamTrack

### activespeakerchanged

ActiveSpeakerDetector new active speaker detected event

#### Parameters

*   `track` **[IncomingStreamTrack][11]** Track that has been activated

### stopped

ActiveSpeakerDetector stopped event

#### Parameters

*   `activeSpeakerDetector` **[ActiveSpeakerDetector][16]** 

## Transponder

**Extends Emitter**

Transponder copies data from an incoming track to an outgoing track and allows stream modifications

### setIncomingTrack

Set incoming track

#### Parameters

*   `track` **[IncomingStreamTrack][11]** Incoming track to attach to
*   `layers` **[Object][3]** \[Optional] Only applicable to video tracks

    *   `layers.encodingId` **[String][1]** rid value of the simulcast encoding of the track (default: first encoding available)
    *   `layers.spatialLayerId` **[Number][4]** The spatial layer id to send to the outgoing stream (default: max layer available)
    *   `layers.temporalLayerId` **[Number][4]** The temporaral layer id to send to the outgoing stream (default: max layer available)
    *   `layers.maxSpatialLayerId` **[Number][4]** Max spatial layer id (default: unlimited)
    *   `layers.maxTemporalLayerId` **[Number][4]** Max temporal layer id (default: unlimited)
*   `smooth` **[Boolean][2]** Wait until next valid frame before switching to the new encoding

### appendH264ParameterSets

Set out of band negotiated H264 parameter sets

#### Parameters

*   `sprop` **[String][1]** H264 parameters sets

### getMedia

Get Transponder media type

Returns **[String][1]** "audio"|"video"

### getIncomingTrack

Get attached track

Returns **[IncomingStreamTrack][11]** track

### getAvailableLayers

Get available encodings and layers

Returns **[Object][3]** 

### getAvailableLayersAsync

Get available encodings and layers

Returns **[Object][3]** 

### isMuted

Check if the track is muted or not

Returns **[boolean][2]** muted

### mute

Mute/Unmute track
This operation will not change the muted state of the stream this track belongs too.

#### Parameters

*   `muting` **[boolean][2]** if we want to mute or unmute

### setIntraOnlyForwarding

Set intra frame forwarding mode

#### Parameters

*   `intraOnlyForwarding` **[boolean][2]** true if you want to forward only intra frames, false otherwise

### setTargetBitrate

Select encoding and temporal and spatial layers based on the desired bitrate. This operation will unmute the transponder if it was mutted and it is possible to select an encoding and layer based on the target bitrate and options.

#### Parameters

*   `target`  
*   `options` **[Object][3]** Options for configuring algorithm to select best encoding/layers \[Optional]

    *   `options.traversal` **[Object][3]** Traversal algorithm "default", "spatial-temporal", "zig-zag-spatial-temporal", "temporal-spatial", "zig-zag-temporal-spatial" \[Default: "default"]
    *   `options.strict` **[Object][3]** If there is not a layer with a bitrate lower thatn target, stop sending media \[Default: false]
    *   `options.smooth` **[Object][3]** When going to a lower simulcast layer, keep the higher one visible \[Default: true]
*   `bitrate` **[Number][4]** 

Returns **[Number][4]** Current bitrate of the selected encoding and layers, it aslo incudes the selected layer indexes and available layers as properties of the Number object.

### setTargetBitrateAsync

Select encoding and temporal and spatial layers based on the desired bitrate. This operation will unmute the transponder if it was mutted and it is possible to select an encoding and layer based on the target bitrate and options.

#### Parameters

*   `target`  
*   `options` **[Object][3]** Options for configuring algorithm to select best encoding/layers \[Optional]

    *   `options.traversal` **[Object][3]** Traversal algorithm "default", "spatial-temporal", "zig-zag-spatial-temporal", "temporal-spatial", "zig-zag-temporal-spatial" \[Default: "default"]
    *   `options.strict` **[Object][3]** If there is not a layer with a bitrate lower thatn target, stop sending media \[Default: false]
    *   `options.smooth` **[Object][3]** When going to a lower simulcast layer, keep the higher one visible \[Default: true]
*   `bitrate` **[Number][4]** 

Returns **any** Promise<{Number}> Current bitrate of the selected encoding and layers, it aslo incudes the selected layer indexes and available layers as properties of the Number object.

### select

Select the simulcast encoding layer and svc layers

#### Parameters

*   `layers` **[Object][3]** \[Optional] Only applicable to video tracks

    *   `layers.encodingId` **[String][1]** rid value of the simulcast encoding of the track (default: the current one)
    *   `layers.spatialLayerId` **[Number][4]** The spatial layer id to send to the outgoing stream (default: max layer available)
    *   `layers.temporalLayerId` **[Number][4]** The temporaral layer id to send to the outgoing stream (default: max layer available)
    *   `layers.maxSpatialLayerId` **[Number][4]** Max spatial layer id (default: unlimited)
    *   `layers.maxTemporalLayerId` **[Number][4]** Max temporal layer id (default: unlimited)
*   `smooth` **[Boolean][2]** Wait until next valid frame before switching to the new encoding

### getSelectedEncoding

Return the encoding that is being forwarded

Returns **[String][1]** encodingId

### getSelectedSpatialLayerId

Return the spatial layer id that is being forwarded

Returns **[Number][4]** spatial layer id

### getSelectedTemporalLayerId

Return the temporal layer id that is being forwarded

Returns **[Number][4]** temporal layer id

### getSelectedLayer

Get current selected layer info

Returns **[Object][3]** 

### getSelectedLayerAsync

Get current selected layer info

Returns **[Object][3]** 

### selectLayer

Select SVC temporatl and spatial layers. Only available for VP9 media.

#### Parameters

*   `spatialLayerId` **[Number][4]** The spatial layer id to send to the outgoing stream
*   `temporalLayerId` **[Number][4]** The temporaral layer id to send to the outgoing stream

### setMaximumLayers

Set maximum statial and temporal layers to be forwrarded. Base layer is always enabled.

#### Parameters

*   `maxSpatialLayerId` **[Number][4]** Max spatial layer id
*   `maxTemporalLayerId` **[Number][4]** Max temporal layer id

### stop

Stop this transponder, will dettach the OutgoingStreamTrack

### muted

Transponder muted event

#### Parameters

*   `transponder` **[Transponder][17]** 

### muted

Transponder muted event

#### Parameters

*   `transponder` **[Transponder][17]** 

### stopped

Transponder stopped event

#### Parameters

*   `transponder` **[Transponder][17]** 

## Recorder

**Extends Emitter**

MP4 recorder that allows to record several streams/tracks on a single mp4 file

### getFilename

Get recording filename

Returns **[String][1]** 

### getStartTime

Get recording filename

Returns **[Date][18]** 

### isTimeShifted

Is the recording time shifted?

Returns **[Boolean][2]** 

### flush

Start recording time shiftt buffer.

#### Parameters

*   `filename` **[String][1]** Override filename \[Optional]

### record

Start recording and incoming

#### Parameters

*   `incomingStreamOrTrack` **([IncomingStream][19] | [IncomingStreamTrack][11])** Incomining stream or track to be recordeds
*   `options`  

Returns **[Array][20]<[RecorderTrack][13]>** 

### mute

Mute/Unmute all tracks
This operation will not change the muted state of the stream this track belongs too.

#### Parameters

*   `muting` **[boolean][2]** if we want to mute or unmute

### stop

Stop recording and close file. NOTE: File will be flsuh async,

Returns **[undefined][21]** TODO: return promise when flush is ended

### started

Recorder started event. This event will be triggered when the first media frame is being recorded.

#### Parameters

*   `recorder` **[Recorder][6]** 
*   `timestamp` **[Number][4]** Timestamp of the first frame in milliseconds

### stopped

Recorder stopped event

#### Parameters

*   `recorder` **[Recorder][6]** 

## Player

**Extends Emitter**

MP4 recorder that allows to record several streams/tracks on a single mp4 file

### getTracks

Get all the tracks

Returns **[Array][20]<[IncomingStreamTrack][11]>** Array of tracks

### getAudioTracks

Get an array of the media stream audio tracks

Returns **[Array][20]<[IncomingStreamTrack][11]>** Array of tracks

### getVideoTracks

Get an array of the media stream video tracks

Returns **[Array][20]<[IncomingStreamTrack][11]>** Array of tracks

### play

Starts playback

#### Parameters

*   `params` **[Object][3]** 

    *   `params.repeat` **[Object][3]** Repeat playback when file is ended

### resume

Resume playback

### pause

Pause playback

### seek

Start playback from given time

#### Parameters

*   `time` **[Number][4]** in miliseconds

### stop

Stop playing and close file

### ended

Playback ended event

#### Parameters

*   `player` **[Player][7]** 

### stopped

Player stopped event

#### Parameters

*   `player` **[Player][7]** 

## StreamerSession

**Extends Emitter**

Represent the connection between a local udp port and a remote one. It sends and/or receive plain RTP data.

### getLocalPort

Get the local rtp/udp port

Returns **[Number][4]** port number

### setRemote

Set the rempte rtp/udp ip and port

#### Parameters

*   `ip`  
*   `port`  

### getIncomingStreamTrack

Returns the incoming stream track associated with this streaming session

Returns **[IncomingStreamTrack][11]** 

### getOutgoingStreamTrack

Returns the outgoing stream track associated with this streaming session

Returns **[OutgoingStreamTrack][22]** 

### stop

Closes udp socket and frees resources

### stopped

StreamerSession stopped event

#### Parameters

*   `session` **[StreamerSession][15]** 

## on

Add event listener

### Parameters

*   `event` **[String][1]** Event name
*   `listeener` **[function][23]** Event listener

Returns **[Transport][9]** 

## once

Add event listener once

### Parameters

*   `event` **[String][1]** Event name
*   `listener` **[function][23]** Event listener

Returns **[IncomingStream][19]** 

## off

Remove event listener

### Parameters

*   `event` **[String][1]** Event name
*   `listener` **[function][23]** Event listener

Returns **[Transport][9]** 

## IncomingStream

**Extends Emitter**

The incoming streams represent the recived media stream from a remote peer.

### getId

The media stream id as announced on the SDP

Returns **[String][1]** 

### getStreamInfo

Get the stream info object for signaling the ssrcs and stream info on the SDP from the remote peer

Returns **StreamInfo** The stream info object

### getStats

Get statistics for all tracks in the stream

See IncomingStreamTrack.getStats for information about the stats returned by each track.

### getStatsAsync

Get statistics for all tracks in the stream

See IncomingStreamTrack.getStats for information about the stats returned by each track.

Returns **any** Promise<{Map<String>,Object}> Map with stats by trackId

### isMuted

Check if the stream is muted or not

Returns **[boolean][2]** muted

### getTrack

Get track by id

#### Parameters

*   `trackId` **[String][1]** The track id

Returns **[IncomingStreamTrack][11]** requested track or null

### getTracks

Get all the tracks

#### Parameters

*   `type` **[String][1]** The media type (Optional)

Returns **[Array][20]<[IncomingStreamTrack][11]>** Array of tracks

### getAudioTracks

Get an array of the media stream audio tracks

Returns **[Array][20]<[IncomingStreamTrack][11]>** Array of tracks

### getVideoTracks

Get an array of the media stream video tracks

Returns **[Array][20]<[IncomingStreamTrack][11]>** Array of tracks

### createTrack

Create new track from a TrackInfo object and add it to this stream

#### Parameters

*   `trackInfo` **TrackInfo** Track info object

Returns **[IncomingStreamTrack][11]** 

### reset

Reset ssrc state of all tracks

### isAttached

Return if the stream is attached or not

### stop

Removes the media strem from the transport and also detaches from any attached incoming stream

### muted

IncomingStream stopped event

#### Parameters

*   `muted` **[boolean][2]** 

### attached

IncomingStream attached event

#### Parameters

*   `incomingStream` **[IncomingStream][19]** 

### attached

IncomingStream attached event

#### Parameters

*   `incomingStream` **[IncomingStream][19]** 

### detached

IncomingStream detached event

#### Parameters

*   `incomingStream` **[IncomingStream][19]** 

### track

IncomingStreamTrack added to stream

#### Parameters

*   `incomingStream` **[IncomingStream][19]** 
*   `incomingStreamTrack` **[IncomingStreamTrack][11]** 

### stopped

IncomingStream stopped event

#### Parameters

*   `incomingStream` **[IncomingStream][19]** 
*   `last` **Objects** stats before closing

## IncomingStreamTrackMirrored

**Extends Emitter**

Mirror incoming stream from another endpoint. Used to avoid inter-thread synchronization when attaching multiple output streams.

### getStats

Get stats for all encodings from the original track

Returns **[Map][24]<[String][1], [Object][3]>** Map with stats by encodingId

### getStatsAsync

Get stats for all encodings from the original track

Returns **[Map][24]<[String][1], [Object][3]>** Map with stats by encodingId

### getActiveLayers

Get active encodings and layers ordered by bitrate of the original track

Returns **[Object][3]** Active layers object containing an array of active and inactive encodings and an array of all available layer info

### getActiveLayersAsync

Get active encodings and layers ordered by bitrate of the original track

Returns **[Object][3]** Active layers object containing an array of active and inactive encodings and an array of all available layer info

### getId

Get track id as signaled on the SDP

### getMediaId

Get track media id (mid)

### getTrackInfo

Get track info object

Returns **TrackInfo** Track info

### getSSRCs

Return ssrcs associated to this track

Returns **[Object][3]** 

### getMedia

Get track media type

Returns **[String][1]** "audio"|"video"

### getEncodings

Get all track encodings
Internal use, you'd beter know what you are doing before calling this method

Returns **[Array][20]<[Object][3]>** encodings
\*

### getEncoding

Get encoding by id
Internal use, you'd beter know what you are doing before calling this method

#### Parameters

*   `encodingId` **[String][1]** encoding Id,

Returns **[Object][3]** encoding
\*

### getDefaultEncoding

Get default encoding
Internal use, you'd beter know what you are doing before calling this method

Returns **[Object][3]** encoding
\*

### isAttached

Return if the track is attached or not

### attached

Signal that this track has been attached.
Internal use, you'd beter know what you are doing before calling this method

### refresh

Request an intra refres on all sources

### detached

Signal that this track has been detached.
Internal use, you'd beter know what you are doing before calling this method

### isMuted

Check if the track is muted or not

Returns **[boolean][2]** muted

### stop

Removes the track from the incoming stream and also detaches any attached outgoing track or recorder

### attached

IncomingStreamTrackMirrored attached event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrackMirrored][25]** 

### attached

IncomingStreamTrackMirrored attached event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrackMirrored][25]** 

### detached

IncomingStreamTrackMirrored dettached event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrackMirrored][25]** 

### detached

IncomingStreamTrackMirrored dettached event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrackMirrored][25]** 

### stopped

IncomingStreamTrack stopped event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrackMirrored][25]** 

### stopped

IncomingStreamTrack stopped event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrackMirrored][25]** 

## OutgoingStream

**Extends Emitter**

The incoming streams represent the media stream sent to a remote peer.

### getStats

Get statistics for all tracks in the stream

See OutgoingStreamTrack.getStats for information about the stats returned by each track.

### getStatsAsync

Get statistics for all tracks in the stream

See OutgoingStreamTrack.getStats for information about the stats returned by each track.

### isMuted

Check if the stream is muted or not

Returns **[boolean][2]** muted

### attachTo

Listen media from the incoming stream and send it to the remote peer of the associated transport.

#### Parameters

*   `incomingStream` **[IncomingStream][19]** The incoming stream to listen media for
*   `layers` **[Object][3]** \[Optional] Only applicable to video tracks

    *   `layers.encodingId` **[String][1]** rid value of the simulcast encoding of the track (default: first encoding available)
    *   `layers.spatialLayerId` **[Number][4]** The spatial layer id to send to the outgoing stream (default: max layer available)
    *   `layers.temporalLayerId` **[Number][4]** The temporaral layer id to send to the outgoing stream (default: max layer available)
    *   `layers.maxSpatialLayerId` **[Number][4]** Max spatial layer id (default: unlimited)
    *   `layers.maxTemporalLayerId` **[Number][4]** Max temporal layer id (default: unlimited)

Returns **[Array][20]<[Transponder][17]>** Track transponders array

### detach

Stop listening for media

### getStreamInfo

Get the stream info object for signaling the ssrcs and stream info on the SDP to the remote peer

Returns **StreamInfo** The stream info object

### getId

The media stream id as announced on the SDP

Returns **[String][1]** 

### getTracks

Get all the tracks

#### Parameters

*   `type` **[String][1]** The media type (Optional)

Returns **[Array][20]<[OutgoingStreamTrack][22]>** Array of tracks

### getTrack

Get track by id

#### Parameters

*   `trackId` **[String][1]** The track id

Returns **[IncomingStreamTrack][11]** requested track or null

### getAudioTracks

Get an array of the media stream audio tracks

Returns **([Array][20] | OutgoingStreamTracks)** Array of tracks

### getVideoTracks

Get an array of the media stream video tracks

Returns **([Array][20] | [OutgoingStreamTrack][22])** Array of tracks

### createTrack

Create new track from a TrackInfo object and add it to this stream

#### Parameters

*   `params` **([Object][3] | TrackInfo | [String][1])** Params plain object, StreamInfo object or media type

    *   `params.id` **[String][1]?** Stream track id
    *   `params.mediaId` **[String][1]?** Stream track media id (mid)
    *   `params.media` **[String][1]?** Media type ("audio" or "video")
    *   `params.ssrcs` **[Object][3]?** Override the generated ssrcs for this track

        *   `params.ssrcs.media` **[Number][4]?** ssrc for the track
        *   `params.ssrcs.rtx` **[Number][4]?** ssrc for the rtx video track
*   `trackInfo` **TrackInfo** Track info object

Returns **[OutgoingStream][26]** The new outgoing stream

Returns **OugoingStreamTrack** 

### muted

OutgoingStreamTrack stopped event

#### Parameters

*   `muted` **[boolean][2]** 

### track

OutgingStreamTrack created

#### Parameters

*   `outgoingStreamTrack` **OutgingStreamTrack** 

### stopped

OutgoingStream stopped event

#### Parameters

*   `outgoingStream` **[OutgoingStream][26]** 
*   `last` **Objects** stats before closing

## PeerConnectionServer

**Extends Emitter**

Manager of remote peer connecion clients

### stop

Stop the peerconnection server, will not stop the transport created by it

### transport

New managed transport has been created by a remote peer connection client

#### Parameters

*   `transport` **[Transport][9]** An initialized transport

### stopped

PeerConnectionServer stopped event

#### Parameters

*   `peerConnectionServer` **[PeerConnectionServer][27]** 

## EmulatedTransport

**Extends Emitter**

An emulated transport reads data from a unencrypted pcap file (typically from a transport dump), and acts like if it was a live transport from a remote peer.
You must create the incoming streams as signaled on the remote SDP as any incoming RTP with an unknown ssrc will be ignored. The emulated transport does not allow creating outgoing streams.

### setRemoteProperties

Set remote RTP properties

#### Parameters

*   `rtp` **([Object][3] | SDPInfo)** Object param containing media information for audio and video

    *   `rtp.audio` **MediaInfo** Audio media info
    *   `rtp.video` **MediaInfo** Video media info

### createIncomingStream

Create an incoming stream object from the media stream info objet

#### Parameters

*   `info` **StreamInfo** Contains the ids and ssrcs of the stream to be created

Returns **[IncomingStream][19]** The newly created incoming stream object

### play

Starts playback

#### Parameters

*   `params` **[Object][3]** 

    *   `params.start` **[Object][3]** Set start time

### resume

Resume playback

### pause

Pause playback

### seek

Start playback from given time

#### Parameters

*   `time` **[Number][4]** in miliseconds

### stop

Stop transport and all the associated incoming and outgoing streams

### stopped

Transport stopped event

#### Parameters

*   `transport` **[EmulatedTransport][28]** 

## Endpoint

**Extends Emitter**

An endpoint represent an UDP server socket.
The endpoint will process STUN requests in order to be able to associate the remote ip:port with the registered transport and forward any further data comming from that transport.
Being a server it is ICE-lite.

### setAffinity

Set cpu affinity for udp send/recv thread.

#### Parameters

*   `cpu` **[Number][4]** CPU core or -1 to reset affinity.

Returns **[boolean][2]** true if operation was successful

### setDefaultSRTProtectionProfiles

setDefaultSRTProtectionProfiles

#### Parameters

*   `srtpProtectionProfiles`  
*   `profiles` **[String][1]** Colon delimited list of SRTP protection profile names

### setRawTx

\[EXPERIMENTAL] See TypeScript typings for usage.

#### Parameters

*   `options`  

### setThreadName

Set name for udp send/recv thread.

Useful for debugging or tracing. Currently only supported
on Linux, fails on other platforms.
Length is limited to 16 bytes.

#### Parameters

*   `name` **[String][1]** thread name to set

Returns **[boolean][2]** true if operation was successful

### setPriority

Set thread priority for udp send/recv thread.
NOTE: User needs to have the appropiate rights to increase the thread priority in ulimit

#### Parameters

*   `priority` **[Number][4]** 0:Normal -19:RealTime

Returns **[boolean][2]** true if operation was successful

### setIceTimeout

Set ICE timeout for outgoing ICE binding requests

#### Parameters

*   `timeout` **[Number][4]** Ammount of time in milliseconds between ICE binding requests

### getLocalPort

Get port at which UDP socket is bound

### createTransport

Create a new transport object and register it with the remote ICE username and password

#### Parameters

*   `remoteInfo` **([Object][3] | SDPInfo)** Remote ICE and DTLS properties

    *   `remoteInfo.ice` **([Object][3] | ICEInfo)** Remote ICE info, containing the username and password.
    *   `remoteInfo.dtls` **([Object][3] | DTLSInfo)** Remote DTLS info
    *   `remoteInfo.candidates` **(Array.CandidateInfo | Array.Object)** Remote ICE candidate info
*   `localInfo` **[Object][3]** Local ICE and DTLS properties (optional)

    *   `localInfo.ice` **ICEInfo** Local ICE info, containing the username and password. Local ICE candidates list is not really used at all.
    *   `localInfo.dtls` **DTLSInfo** Local DTLS info
    *   `localInfo.candidates` **Array.CandidateInfo** Local candidate info
*   `options` **[Object][3]** Dictionary with transport properties

    *   `options.disableSTUNKeepAlive` **[boolean][2]** Disable ICE/STUN keep alives, required for server to server transports
    *   `options.srtpProtectionProfiles` **[String][1]** Colon delimited list of SRTP protection profile names
    *   `options.overrideBWE` **[boolean][2]** Override BWE reported by REMB
    *   `options.disableREMB` **[boolean][2]** Disable REMB BWE calculation.
    *   `options.prefferDTLSSetupActive` **[boolean][2]** Preffer setting local DTLS setup to 'active' if remote is 'actpass'.

Returns **[Transport][9]** New transport object

### getLocalCandidates

Get local ICE candidates for this endpoint. It will be shared by all the transport associated to this endpoint.

Returns **Array.CandidateInfo** 

### getDTLSFingerprint

Get local DTLS fingerprint for this endpoint. It will be shared by all the transport associated to this endpoint.

Returns **[String][1]** 

### createOffer

Helper that creates an offer from capabilities
It generates a random ICE username and password and gets endpoint fingerprint

#### Parameters

*   `capabilities` **[Object][3]** Media capabilities as required by SDPInfo.create

Returns **SDPInfo** SDP offer

### createPeerConnectionServer

Create new peer connection server to manage remote peer connection clients

#### Parameters

*   `tm` **TransactionManager** 
*   `capabilities` **[Object][3]** Same as SDPInfo.answer capabilites

Returns **[PeerConnectionServer][27]** 

### createActiveSpeakerMultiplexer

Create new active speaker multiplexer for given outgoing tracks

#### Parameters

*   `streamOrTracks` **([OutgoingStream][26] | Array.OutgoingStreamTrack)** Outgoing stream or outgoing stream track array to be multiplexed

Returns **[ActiveSpeakerMultiplexer][12]** 

### mirrorIncomingStream

Mirror incoming stream from another endpoint. Used to avoid inter-thread synchronization when attaching multiple output streams.
The endpoint will cache the cucrrent mirrored streams and return an already existing object if calling this method twice with same stream.

#### Parameters

*   `incomingStream` **[IncomingStream][19]** stream to mirror

Returns **[IncomingStream][19]** mirrored stream.

### mirrorIncomingStreamTrack

Mirror incoming stream track from another endpoint. Used to avoid inter-thread synchronization when attaching multiple output tracks.
The endpoint will cache the cucrrent mirrored tracks and return an already existing object if calling this method twice with same track.

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** track to mirror

Returns **[IncomingStreamTrackMirrored][25]** mirrored track.

### createSDPManager

Create new SDP manager, this object will manage the SDP O/A for you and produce a suitable trasnport.

#### Parameters

*   `sdpSemantics` **[String][1]** Type of sdp plan "unified-plan" or "plan-b"
*   `capabilities` **[Object][3]** Capabilities objects

Returns **[SDPManager][10]** 

### stop

Stop the endpoint UDP server and terminate any associated transport

### stopped

Endpoint stopped event

#### Parameters

*   `endpoint` **[Endpoint][5]** 

## Transport

**Extends Emitter**

A transport represent a connection between a local ICE candidate and a remote set of ICE candidates over a single DTLS session.
The transport object will internally allocate the ICE and DTLS information of the local side in order to signal it to the remote side and establish the connection.
Each transport has a set of incoming and outgoing streams that allow to send or receive RTP streams to the remote peer.
You must create the incoming streams as signaled on the remote SDP as any incoming RTP with an unknown ssrc will be ignored.
When you create an outgoing stream, the transport will allocate internally the ssrcs for the different RTP streams in order to avoid collision. You will be able to retrieve that information from the streams object in order to be able to announce them on the SDP sent to the remote side.
In order to decide how to route your streams you must attach the outgoing streams from one transport to the incoming streams of other (or same) transport.

### dump

Dump incoming and outgoint rtp and rtcp packets into a pcap file

#### Parameters

*   `filename` **[String][1]** Filename of the pcap file
*   `options` **[Object][3]** Dump parameters (optional)

    *   `options.incoming` **[Boolean][2]** Dump incomoning RTP data
    *   `options.outgoing` **[Boolean][2]** Dump outgoing RTP data
    *   `options.rtcp` **[Boolean][2]** Dump rtcp RTP data
    *   `options.rtpHeadersOnly` **[Boolean][2]** Dump only rtp headers and first 16 bytes of payload for rtp packets
    *   `options.bwe` **[Boolean][2]** Dump bwe stats to a different file (.pcap->.csv)

### stopDump

Stop dumping transport rtp and rtcp packets

### getStats

Get transport stats

*   senderSideEstimationBitrate    : Sneder side estimation bitrate (if available)
*   ice      : ICE related stats

<!---->

*   requestsSent		: Number of ice requests sent
*   requestsReceived	: Number of ice requests received
*   responsesSent		: Number of ice responses sent
*   responsesReceived	: Number of ice responses received

Returns **[Object][3]** stats

### restartICE

Restart ICE on transport object

#### Parameters

*   `remoteICE` **([Object][3] | ICEInfo)** Remote ICE info, containing the username and password.
*   `localICE` **([Object][3] | ICEInfo)** Local ICE info, containing the username and password \[Optional]

Returns **ICEInfo** Local ICE info

### getAvailableOutgoingBitrate

Get available outgoing bitrate in bps.

Returns **Nummber** 

### getEstimatedBitrate

Get bandwidth estimation in bps.

Returns **Nummber** 

### getTotalSentBitrate

Get current sent bitrate

Returns **Nummber** 

### setBandwidthProbing

Enable bitrate probing.
This will send padding only RTX packets to allow bandwidth estimation algortithm to probe bitrate beyonf current sent values.
The ammoung of probing bitrate would be limited by the sender bitrate estimation and the limit set on the setMaxProbing Bitrate.
Note that this will only work on browsers that supports RTX and transport wide cc.

#### Parameters

*   `probe` **Boolen** 

### setMaxProbingBitrate

Set the maximum bitrate to be used if probing is enabled.

#### Parameters

*   `bitrate` **[Number][4]** 

### enableSenderSideEstimation

Enable or disable calculation of sender side estimation if transport wide cc has been negotiated

#### Parameters

*   `enabled` **[Boolean][2]** 

### setRemoteOverrideBitrate

Override the bitrate sent by REMB to the remote sender. The transport must be constructed with teh override bwe option, and transport wide cc must not be offered.

#### Parameters

*   `bitrate` **[Number][4]** 

### setProbingBitrateLimit

Do not allow probing to increase sent bitrate above certain limit

#### Parameters

*   `bitrate` **[Number][4]** limit

### setLocalProperties

Set local RTP properties

#### Parameters

*   `rtp` **([Object][3] | SDPInfo)** Object param containing media information for audio and video

    *   `rtp.audio` **MediaInfo** Audio media info
    *   `rtp.video` **MediaInfo** Video media info

### setRemoteProperties

Set remote RTP properties

#### Parameters

*   `rtp` **([Object][3] | SDPInfo)** Object param containing media information for audio and video

    *   `rtp.audio` **MediaInfo** Audio media info
    *   `rtp.video` **MediaInfo** Video media info

### getDTLSState

Get current dtls state for transport

Returns **[String][1]** DTLS connection state as per the w3c spec  "new", "connecting", "connected", "closed", "failed"

### getLocalDTLSInfo

Get transport local DTLS info

Returns **DTLSInfo** DTLS info object

### getLocalICEInfo

Get transport local ICE info

Returns **ICEInfo** ICE info object

### getLocalCandidates

Get local ICE candidates for this transport

Returns **Array.CandidateInfo** 

### getRemoteDTLSInfo

Get transport remote DTLS info

Returns **DTLSInfo** DTLS info object

### getRemoteICEInfo

Get transport remote ICE info

Returns **ICEInfo** ICE info object

### getRemoteCandidates

Get remote ICE candidates for this transport

Returns **Array.CandidateInfo** 

### addRemoteCandidate

Register a remote candidate info. Only needed for ice-lite to ice-lite endpoints

#### Parameters

*   `candidate` **CandidateInfo** 

Returns **[boolean][2]** Wheter the remote ice candidate was alrady presnet or not

### addRemoteCandidates

Register an array remote candidate info. Only needed for ice-lite to ice-lite endpoints

#### Parameters

*   `candidates` **Array.CandidateInfo** 

### createOutgoingStream

Create new outgoing stream in this transport

#### Parameters

*   `params` **([Object][3] | StreamInfo | [String][1])** Params plain object, StreamInfo object or stream id

    *   `params.audio` **([Array][20]<[Object][3]> | [Object][3] | [boolean][2])** Add audio track to the new stream

        *   `params.audio.id` **[Object][3]?** Stream track id (default: "audio")
        *   `params.audio.ssrcs` **[Number][4]?** Override the generated ssrcs for this track

            *   `params.audio.ssrcs.media` **[Number][4]?** ssrc for the audio track
    *   `params.id` **[Object][3]?** Stream id, an UUID will be generated if not provided
    *   `params.video` **([Array][20]<[Object][3]> | [Object][3] | [boolean][2])** Add video track to the new stream

        *   `params.video.id` **[Object][3]?** Stream track id (default: "video")
        *   `params.video.ssrcs` **[Object][3]?** Override the generated ssrcs for this track

            *   `params.video.ssrcs.media` **[Number][4]?** ssrc for the video track
            *   `params.video.ssrcs.rtx` **[Number][4]?** ssrc for the rtx video track

Returns **[OutgoingStream][26]** The new outgoing stream

### createOutgoingStreamTrack

Create new outgoing stream in this transport

#### Parameters

*   `media` **[String][1]** Track media type "audio" or "video"
*   `params` **[Object][3]?** Track parameters

    *   `params.id` **[Object][3]?** Stream track id
    *   `params.mediaId` **[Object][3]?** Stream track media id (mid)
    *   `params.ssrcs` **[Number][4]?** Override the generated ssrcs for this track

        *   `params.ssrcs.media` **[Number][4]?** ssrc for the media track
        *   `params.ssrcs.rtx` **[Number][4]?** ssrc for the rtx track

Returns **[OutgoingStreamTrack][22]** The new outgoing stream track

### createIncomingStream

Create an incoming stream object from the media stream info objet

#### Parameters

*   `info` **(StreamInfo | [Object][3] | [String][1])** Contains the ids and ssrcs of the stream to be created

Returns **[IncomingStream][19]** The newly created incoming stream object

### getIncomingStreams

Get all the incoming streams in the transport

Returns **[Array][20]\<IncomingStreams>** 

### getIncomingStream

Get incoming stream

#### Parameters

*   `streamId` **[String][1]** the stream ID

Returns **[IncomingStream][19]** 

### getOutgoingStreams

Get all the outgoing streams in the transport

Returns **[Array][20]\<OutgoingStreams>** 

### getOutgoingStream

Get incoming stream

#### Parameters

*   `streamId` **[String][1]** the stream ID

Returns **[IncomingStream][19]** 

### createIncomingStreamTrack

Create new incoming stream in this transport. TODO: Simulcast is still not supported

#### Parameters

*   `media` **[String][1]** Track media type "audio" or "video"
*   `params` **[Object][3]?** Track parameters

    *   `params.id` **[Object][3]?** Stream track id
    *   `params.mediaId` **[Object][3]?** Stream track media id (mid)
    *   `params.ssrcs` **[Number][4]?** Override the generated ssrcs for this track

        *   `params.ssrcs.media` **[Number][4]?** ssrc for the media track
        *   `params.ssrcs.rtx` **[Number][4]?** ssrc for the rtx track

Returns **[IncomingStreamTrack][11]** The new incoming stream track

### publish

Create new outgoing stream and attach to the incoming stream

#### Parameters

*   `incomingStream` **[IncomingStream][19]** the incoming stream to be published in this transport

Returns **[OutgoingStream][26]** The new outgoing stream

### stop

Stop transport and all the associated incoming and outgoing streams

### icetimeout

ICE timoute event. Fired when no ICE request ar received for 30 seconds.

#### Parameters

*   `transport` **[Transport][9]** 

### dtlsstate

DTLS State change event

#### Parameters

*   `dtlsstate` **[String][1]** DTLS connection state as per the w3c spec  "new", "connecting", "connected", "closed", "failed"
*   `transport` **[Transport][9]** 

### remoteicecandidate

ICE remote candidate activation event.
This event fires when ICE candidate has correctly being checked out and we start using it for sending.

#### Parameters

*   `candidate` **CandidateInfo** The ip and port of the remote ICE candidate that is in use by the transport
*   `transport` **[Transport][9]** 

### targetbitrate

Transport sender side estimation bitrate target udpate

#### Parameters

*   `targetBitrate` **Integer** 
*   `bandwidthEstimation` **Integer** 
*   `totalBitrate` **Integer** 
*   `transport` **[Transport][9]** 

### outgoingtrack

New outgoing stream track added to transport

#### Parameters

*   `track` **[OutgoingStreamTrack][22]** 
*   `stream` **[OutgoingStream][26]?** 

### incomingtrack

New incoming stream track added to transport

#### Parameters

*   `track` **[IncomingStreamTrack][11]** 
*   `stream` **[IncomingStream][19]** 

### stopped

Transport stopped event

#### Parameters

*   `transport` **[Transport][9]** 

## parseIPv4

parse a dot-separated IPv4 into a normalized address as u32be

### Parameters

*   `ip`  

## stopped

AudioDecoder stopped event

### Parameters

*   `frame` **[Object][3]** 
*   `reader` **IncomingStreamTrackReader** 

## stopped

AudioDecoder stopped event

### Parameters

*   `reader` **IncomingStreamTrackReader** 

## parseCIDR

parse a CIDR into a normalized \[address as u32be, prefix length] tuple

### Parameters

*   `cidr`  

## OutgoingStreamTrack

**Extends Emitter**

Audio or Video track of a media stream sent to a remote peer

### getId

Get track id as signaled on the SDP

### getMediaId

Get track media id (mid)

### getMedia

Get track media type

Returns **[String][1]** "audio"|"video"

### getTrackInfo

Get track info object

Returns **TrackInfo** Track info

### getStats

Get stats for all encodings

You will get stats for media and rtx sources (if used):

*   timestmap		: timestamp on when this stats where created
*   media		: mediaStats,
*   rtx		: rtxStats,
*   remb		: remote estimated bitate (if remb is in use)
*   numPackets	: number of rtp packets sent
*   numPacketsDelta	: number of rtp packets sent during last second
*   bitrate		: Bitrate for media stream only in bps
*   total		: Accumulated bitrate for media and rtx streams in bps

The stats objects will privide the follwing info for each source

*   numFrames			: total recevied frames
*   numFramesDelta		: recevied frames during last second
*   numPackets		: number of rtp packets sent
*   numPacketsDelta		: number of rtp packets sent during last second
*   numRTCPPackets		: number of rtcp packsets sent
*   totalBytes		: total rtp sent bytes
*   totalRTCPBytes		: total rtp sent bytes
*   bitrate			: average bitrate sent during last second in bps
*   reportCount		: number of RTCP receiver reports received
*   reportCountDelta		: number of RTCP receiver reports received during last second
*   reportedLostCount		: total packet loses reported
*   reportedLostCountDelta	: packet losses reported in last second
*   reportedFractionLost	: fraction loss media reported during last second
*   reportedJitter		: last reported jitter buffer value

Returns **[Map][24]<[String][1], [Object][3]>** Map with stats by encodingId

### getStatsAsync

Get stats for all encodings

You will get stats for media and rtx sources (if used):

*   timestmap		: timestamp on when this stats where created
*   media		: mediaStats,
*   rtx		: rtxStats,
*   remb		: remote estimated bitate (if remb is in use)
*   numPackets	: number of rtp packets sent
*   numPacketsDelta	: number of rtp packets sent during last second
*   bitrate		: Bitrate for media stream only in bps
*   total		: Accumulated bitrate for media and rtx streams in bps

The stats objects will privide the follwing info for each source

*   numFrames			: total recevied frames
*   numFramesDelta		: recevied frames during last second
*   numPackets		: number of rtp packets sent
*   numPacketsDelta		: number of rtp packets sent during last second
*   numRTCPPackets		: number of rtcp packsets sent
*   totalBytes		: total rtp sent bytes
*   totalRTCPBytes		: total rtp sent bytes
*   bitrate			: average bitrate sent during last second in bps
*   reportCount		: number of RTCP receiver reports received
*   reportCountDelta		: number of RTCP receiver reports received during last second
*   reportedLostCount		: total packet loses reported
*   reportedLostCountDelta	: packet losses reported in last second
*   reportedFractionLost	: fraction loss media reported during last second
*   reportedJitter		: last reported jitter buffer value

Returns **[Map][24]<[String][1], [Object][3]>** Map with stats by encodingId

### getSSRCs

Return ssrcs associated to this track

Returns **[Object][3]** 

### isMuted

Check if the track is muted or not

Returns **[boolean][2]** muted

### isAttached

Check if this outgoing stream track is alredy attached to an incoming stream track.

Returns **[Boolean][2]** true if attached, false otherwise

### createTransponder

Create a transponder if not already attached or return current one.

Returns **[Transponder][17]** Track transponder object

### attachTo

Listen media from the incoming stream track and send it to the remote peer of the associated transport.
This will stop any previous transpoder created by a previous attach.

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** The incoming stream to listen media for
*   `layers` **[Object][3]** \[Optional] Only applicable to video tracks

    *   `layers.encodingId` **[String][1]** rid value of the simulcast encoding of the track (default: first encoding available)
    *   `layers.spatialLayerId` **[Number][4]** The spatial layer id to send to the outgoing stream (default: max layer available)
    *   `layers.temporalLayerId` **[Number][4]** The temporaral layer id to send to the outgoing stream (default: max layer available)
    *   `layers.maxSpatialLayerId` **[Number][4]** Max spatial layer id (default: unlimited)
    *   `layers.maxTemporalLayerId` **[Number][4]** Max temporal layer id (default: unlimited)

Returns **[Transponder][17]** Track transponder object

### detach

Stop forwarding any previous attached track.
This will set the transponder inconming track to null

### getTransponder

Get attached transpoder for this track

Returns **[Transponder][17]** Attached transpoder or null if not attached

### stop

Removes the track from the outgoing stream and also detaches from any attached incoming track

### remb

OutgoingStreamTrack remb event

#### Parameters

*   `outgoingStreamTrack` **[OutgoingStreamTrack][22]** 
*   `bitrate` **[Number][4]** estimation

### muted

OutgoingStreamTrack stopped event

#### Parameters

*   `muted` **[boolean][2]** 

### muted

IncomingStreamTrack stopped event

#### Parameters

*   `muted` **[boolean][2]** 

### muted

IncomingStreamTrack stopped event

#### Parameters

*   `muted` **[boolean][2]** 

### muted

IncomingStreamTrack stopped event

#### Parameters

*   `muted` **[boolean][2]** 

### stopped

OutgoingStreamTrack stopped event

#### Parameters

*   `outgoingStreamTrack` **[OutgoingStreamTrack][22]** 

## IncomingStreamTrack

**Extends Emitter**

Audio or Video track of a remote media stream

### getStatsAsync

Get stats for all encodings

For each encoding you will get stats for media and rtx sources (if used):

*   media    : Stats for the media stream
*   rtx      : Stats for the rtx retransmission stream
*   rtt      : Round Trip Time in ms
*   waitTime : "min","max" and "avg" packet waiting times in rtp buffer before delivering them
*   bitrate  : Bitrate for media stream only in bps
*   total    : Accumulated bitrate for media and rtx streams in bps
*   remb     : Estimated avialable bitrate for receving (only avaailable if not using tranport wide cc)
*   timestamp: When this stats was generated, in order to save workload, stats are cached for 200ms
*   simulcastIdx	: Simulcast layer index based on bitrate received (-1 if it is inactive).
*   lostPackets	: Accumulated lost packets for media and rtx strems
*   numPackets	: Accumulated packets for media and rtx strems
*   lostPacketsRatio	: Lost packets ratio

The stats objects will provide the following info for each source

*   numFrames		: total recevied frames
*   numFramesDelta	: recevied frames during last second
*   lostPackets	: total lost packkets
*   lostPacketsDelta	: Lost/out of order packets during last second
*   lostPacketsMaxGap	: max total consecutieve packets lossed during last second
*   lostPacketsGapCount : number of packet looses bursts during last second
*   dropPackets       : droppted packets by media server
*   numPackets	: number of rtp packets received
*   numPacketsDelta	: number of rtp packets received during last seconds
*   numRTCPPackets	: number of rtcp packsets received
*   totalBytes	: total rtp received bytes
*   totalRTCPBytes	: total rtp received bytes
*   totalPLIs		: total PLIs sent
*   totalNACKs	: total NACk packets sent
*   bitrate		: average bitrate received during last second in bps
*   skew		: difference between NTP timestamp and RTP timestamps at sender (from RTCP SR)
*   drift		: ratio between RTP timestamps and the NTP timestamp and  at sender (from RTCP SR)
*   clockRate		: RTP clockrate
*   frameDelay	: Average frame delay during the last second
*   frameDelayMax	: Max frame delay during the last second
*   frameCaptureDelay		: Average bewtween local reception time and sender capture one (Absolute capture time must be negotiated)
*   frameCaptureDelayMax	: Max bewtween local reception time and sender capture one (Absolute capture time must be negotiated)
*   width		: video width
*   height		: video height
*   layers		: Information about each spatial/temporal layer (if present)
    *   spatialLayerId  : Spatial layer id
    *   temporalLayerId : Temporatl layer id
    *   totalBytes	: total rtp received bytes for this layer
    *   numPackets	: number of rtp packets received for this layer
    *   bitrate		: average bitrate received during last second for this layer
    *   targetBitrate	: Signaled target bitrate on the VideoLayersAllocation header
    *   targetWidth	: Signaled target width on the VideoLayersAllocation header
    *   targetHeight	: Signaled target height on the VideoLayersAllocation header
    *   targetFps	: Signaled target fps on the VideoLayersAllocation header

Returns **any** Promise<{Map\<String,Object>}> Promise resolving to a map with stats by encodingId

### getStats

Get stats for all encodings

For each encoding you will get stats for media and rtx sources (if used):

*   media    : Stats for the media stream
*   rtx      : Stats for the rtx retransmission stream
*   rtt      : Round Trip Time in ms
*   waitTime : "min","max" and "avg" packet waiting times in rtp buffer before delivering them
*   bitrate  : Bitrate for media stream only in bps
*   total    : Accumulated bitrate for media and rtx streams in bps
*   remb     : Estimated avialable bitrate for receving (only avaailable if not using tranport wide cc)
*   timestamp: When this stats was generated, in order to save workload, stats are cached for 200ms
*   simulcastIdx	: Simulcast layer index based on bitrate received (-1 if it is inactive).
*   lostPackets	: Accumulated lost packets for media and rtx strems
*   numPackets	: Accumulated packets for media and rtx strems
*   lostPacketsRatio	: Lost packets ratio

The stats objects will provide the following info for each source

*   numFrames		: total recevied frames
*   numFramesDelta	: recevied frames during last second
*   lostPackets	: total lost packkets
*   lostPacketsDelta	: Lost/out of order packets during last second
*   lostPacketsMaxGap	: max total consecutieve packets lossed during last second
*   lostPacketsGapCount : number of packet looses bursts during last second
*   dropPackets       : droppted packets by media server
*   numPackets	: number of rtp packets received
*   numPacketsDelta	: number of rtp packets received during last seconds
*   numRTCPPackets	: number of rtcp packsets received
*   totalBytes	: total rtp received bytes
*   totalRTCPBytes	: total rtp received bytes
*   totalPLIs		: total PLIs sent
*   totalNACKs	: total NACk packets sent
*   bitrate		: average bitrate received during last second in bps
*   skew		: difference between NTP timestamp and RTP timestamps at sender (from RTCP SR)
*   drift		: ratio between RTP timestamps and the NTP timestamp and  at sender (from RTCP SR)
*   clockRate		: RTP clockrate
*   frameDelay	: Average frame delay during the last second
*   frameDelayMax	: Max frame delay during the last second
*   frameCaptureDelay		: Average bewtween local reception time and sender capture one (Absolute capture time must be negotiated)
*   frameCaptureDelayMax	: Max bewtween local reception time and sender capture one (Absolute capture time must be negotiated)
*   width		: video width
*   height		: video height
*   layers		: Information about each spatial/temporal layer (if present)
    *   spatialLayerId  : Spatial layer id
    *   temporalLayerId : Temporatl layer id
    *   totalBytes	: total rtp received bytes for this layer
    *   numPackets	: number of rtp packets received for this layer
    *   bitrate		: average bitrate received during last second for this layer

Returns **[Map][24]<[String][1], [Object][3]>** Map with stats by encodingId

### getActiveLayers

Get active encodings and layers ordered by bitrate

Returns **[Object][3]** Active layers object containing an array of active and inactive encodings and an array of all available layer info

### getActiveLayersAsync

Get active encodings and layers ordered by bitrate

Returns **any** Promise<{Object}> Active layers object containing an array of active and inactive encodings and an array of all available layer info

### getId

Get track id as signaled on the SDP

### getMediaId

Get track media id

### getTrackInfo

Get track info object

Returns **TrackInfo** Track info

### getSSRCs

Return ssrcs associated to this track

Returns **[Object][3]** 

### getMedia

Get track media type

Returns **[String][1]** "audio"|"video"

### getEncodings

Get all track encodings
Internal use, you'd beter know what you are doing before calling this method

Returns **[Array][20]<[Object][3]>** encodings
\*

### getEncoding

Get encoding by id
Internal use, you'd beter know what you are doing before calling this method

#### Parameters

*   `encodingId` **[String][1]** encoding Id,

Returns **[Object][3]** encoding
\*

### getDefaultEncoding

Get default encoding
Internal use, you'd beter know what you are doing before calling this method

Returns **[Object][3]** encoding
\*

### attached

Signal that this track has been attached.
Internal use, you'd beter know what you are doing before calling this method

### refresh

Request an intra refres on all sources

### reset

Reset state of incoming sources

### isMuted

Check if the track is muted or not

Returns **[boolean][2]** muted

### isAttached

Return if the track is attached or not

### detached

Signal that this track has been detached.
Internal use, you'd beter know what you are doing before calling this method

### setH264ParameterSets

Store out of band h264 properties for this track

#### Parameters

*   `sprop` **[String][1]** Base64 encoded parameters from SDP

### hasH264ParameterSets

Check if track has out of band h264 properties

Returns **[Boolean][2]** 

### getH264ParameterSets

Get out of band h264 parameters from this track

Returns **[Boolean][2]** 

### setMaxWaitTime

Override the maximum period of time to wait for an out of order or rtx packet

#### Parameters

*   `maxWaitTime` **[Number][4]** max wait time in ms (default: 0 if rtx is not supported or rtt based)

### resetMaxWaitTime

Remove override for the maximum period of time to wait for an out of order or rtx packet

### stop

Removes the track from the incoming stream and also detaches any attached outgoing track or recorder

### encoding

IncomingStreamTrack new encoding event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** 
*   `encoding` **[Object][3]** 

### encoding

IncomingStreamTrack new encoding event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** 
*   `encoding` **[Object][3]** 

### attached

IncomingStreamTrack attached event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** 

### detached

IncomingStreamTrack detached event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** 

### stopped

IncomingStreamTrack stopped event

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** 

## withSocket

Create a dedicated socket on each query, no caching... it's inefficient
but more robust, we don't need to give user a way to invalidate the cache,
we don't need to be careful when managing refs, subscriptions...

### Parameters

*   `callback`  

## IncomingStreamTrackSimulcastAdapter

**Extends Emitter**

Bundle multiple video track as if they were a single simulcast video track

### addTrack

Add video track to the simulcast adapter

#### Parameters

*   `encodingId` **[String][1]** Id used as base for encodings id
*   `incomingStreamTrack` **[IncomingStreamTrack][11]** Incoming video stream track

### removeTrack

Remove video track to the simulcast adapter

#### Parameters

*   `incomingStreamTrack` **[IncomingStreamTrack][11]** Incoming video stream track

### getStats

Get stats for all encodings from the original track

Returns **[Map][24]<[String][1], [Object][3]>** Map with stats by encodingId

### getStatsAsync

Get stats for all encodings from the original track

Returns **any** Promise<{Map\<String,Object>}> Map with stats by encodingId

### getActiveLayers

Get active encodings and layers ordered by bitrate of the original track

Returns **[Object][3]** Active layers object containing an array of active and inactive encodings and an array of all available layer info

### getActiveLayersAsync

Get active encodings and layers ordered by bitrate of the original track

Returns **[Object][3]** Active layers object containing an array of active and inactive encodings and an array of all available layer info

### getId

Get track id as signaled on the SDP

### getMediaId

Get track media id (mid)

### getTrackInfo

Get track info object

Returns **TrackInfo** Track info

### getSSRCs

Return ssrcs associated to this track

Returns **[Object][3]** 

### getMedia

Get track media type

Returns **[String][1]** "audio"|"video"

### getEncodings

Get all track encodings
Internal use, you'd beter know what you are doing before calling this method

Returns **[Array][20]<[Object][3]>** encodings
\*

### getEncoding

Get encoding by id
Internal use, you'd beter know what you are doing before calling this method

#### Parameters

*   `encodingId` **[String][1]** encoding Id,

Returns **[Object][3]** encoding
\*

### getDefaultEncoding

Get default encoding
Internal use, you'd beter know what you are doing before calling this method

Returns **[Object][3]** encoding
\*

### isMuted

Check if the track is muted or not

Returns **[boolean][2]** muted

### isAttached

Return if the track is attached or not

### attached

Signal that this track has been attached.
Internal use, you'd beter know what you are doing before calling this method

### refresh

Request an intra refres on all sources

### detached

Signal that this track has been detached.
Internal use, you'd beter know what you are doing before calling this method

### stop

Removes the track from the incoming stream and also detaches any attached outgoing track or recorder

## extractOne

### Parameters

*   `list`  
*   `name`  

## collectRoutingInfoWithRoute

Continuation of collectRoutingInfo once a route has been
selected (split to allow reusal from getInterfaceRawConfig).

### Parameters

*   `rtNetlink`  
*   `ifindex` **[number][4]** Interface
*   `route`  
*   `dst` **[number][4]** Resolved next hop address for route

[1]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String

[2]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean

[3]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object

[4]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number

[5]: #endpoint

[6]: #recorder

[7]: #player

[8]: #streamer

[9]: #transport

[10]: #sdpmanager

[11]: #incomingstreamtrack

[12]: #activespeakermultiplexer

[13]: #recordertrack

[14]: #refresher

[15]: #streamersession

[16]: #activespeakerdetector

[17]: #transponder

[18]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Date

[19]: #incomingstream

[20]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array

[21]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/undefined

[22]: #outgoingstreamtrack

[23]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Statements/function

[24]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Map

[25]: #incomingstreamtrackmirrored

[26]: #outgoingstream

[27]: #peerconnectionserver

[28]: #emulatedtransport
